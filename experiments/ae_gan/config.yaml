project_name : "ae_gan_night"
experiment_name : "ae_attn_512"
experiment_path : "experiments/ae_gan"

ConvAutoencoder:
  latent_dim: 512
ConvAutoencoder2:
  latent_dim: 256
AttentionChargedAutoencoder:
  latent_dim: 512

model:
  name: "convautoencoder"
#can be "convautoencoder", "convautoencoder2", "attentionchargedautoencoder"
  
  
lpips:
  disc_start: 1.0
  disc_weight: 0.0
  disc_in_channels: 1
  disc_num_layers: 3
  use_actnorm: false
  perceptual_weight: 0.0

# dataset
dataset:
  name: sevir
  data_dir: "/home/vatsal/NWM/sevir_lr"
  seq_len: 1
  sample_mode: "sequent"
  stride: 1
  layout: "NHWT"
  rescale_method: "01"
  preprocess: true
  verbose: false
  aug_mode: "0"
  ret_contiguous: true
  batch_size: 16
  num_workers: 8

  seed: 0
  val_ratio: 0.1
  start_data: null
  train_test_split_date: 2019-06-01
  end_data: null
  input_frames: 1
  pred_frames: 1
  raw_seq_len: 13
  interval_real_time: 5
  image_width: 128
  image_height: 128
  channels: 1

# optimizer
optim:
  lr : 1e-4
  weight_decay : 1e-3
  gradient_clip_val : 1.0

# lr scheduler
cosine_warmup:
  start_lr: 1e-5
  peak_lr: 1e-4
  final_lr: 1e-6
  warmup_ratio: 0.1

one_cycle:
  peak_lr : 1e-3
  start_lr: 4e-5
  final_lr: 4e-7
  rampup_ratio: 0.3

lr_range_test:
  max_lr: 1
  num_iter: 100

# trainer
trainer:
  devices: [0]
  max_epochs: 50
  accumulate_grad_batches: 1
  total_train_steps : -1 # need to be set
  total_val_steps : -1 # need to be set
  total_test_steps : -1 # need to be set
  save_every_n_steps: 0.1
  save_on_train_epoch_end: true
  limit_train_batches: 0.1
  limit_val_batches: 0.1
  limit_test_batches: 0.1
  log_every_n_steps: 1

# logging
logging:
  wandb_watch_log_freq: 0
  log_train_all_metrics_n : 0.01
  log_train_plots_n : 0.1
  log_val_plots_n : 0.1