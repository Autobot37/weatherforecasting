{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline.datasets.sevir.sevir import SEVIRLightningDataModule\n",
    "import time\n",
    "from omegaconf import OmegaConf\n",
    "cfg = OmegaConf.load(\"/home/vatsal/NWM/weatherforecasting/pipeline/datasets/sevir/config.yaml\").Dataset\n",
    "dm = SEVIRLightningDataModule(cfg)\n",
    "dm.prepare_data()\n",
    "setup_s = time.time()\n",
    "dm.setup()\n",
    "setup_e = time.time()\n",
    "print(f\"took : {setup_e - setup_s}\")\n",
    "\n",
    "l_s = time.time()\n",
    "loader = dm.train_dataloader()\n",
    "idx = 0\n",
    "for sample in loader:\n",
    "    idx += 1\n",
    "    if idx >= 200:break\n",
    "l_e = time.time()\n",
    "print(\"loading\", l_e - l_s)\n",
    "l_train_full = len(dm.train_dataloader())\n",
    "l_val_full = len(dm.val_dataloader())\n",
    "l_test_full = len(dm.test_dataloader())\n",
    "print(l_train_full, l_val_full, l_test_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline.datasets.sevir.sevir import SEVIRLightningDataModule\n",
    "import time\n",
    "from omegaconf import OmegaConf\n",
    "cfg = OmegaConf.load(\"/home/vatsal/NWM/weatherforecasting/pipeline/datasets/sevir/fast_config.yaml\").Dataset\n",
    "dm = SEVIRLightningDataModule(cfg)\n",
    "dm.prepare_data()\n",
    "setup_s = time.time()\n",
    "dm.setup()\n",
    "setup_e = time.time()\n",
    "print(f\"took : {setup_e - setup_s}\")\n",
    "\n",
    "l_s = time.time()\n",
    "loader = dm.train_dataloader()\n",
    "idx = 0\n",
    "for sample in loader:\n",
    "    idx += 1\n",
    "    if idx >= 200:break\n",
    "l_e = time.time()\n",
    "print(\"loading\", l_e - l_s)\n",
    "l_train_fast = len(dm.train_dataloader())\n",
    "l_val_fast = len(dm.val_dataloader())\n",
    "l_test_fast = len(dm.test_dataloader())\n",
    "print(l_train_fast, l_val_fast, l_test_fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(l_train_fast/l_train_full)\n",
    "print(l_val_fast/l_val_full)\n",
    "print(l_test_fast/l_test_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummpy = torch.randn(8, 52, 2304)\n",
    "from omegaconf import OmegaConf\n",
    "cfg = OmegaConf.load(\"/home/vatsal/NWM/weatherforecasting/experiments/pretrained_ae_dlinear_indc_indp/config.yaml\").dlinear\n",
    "model = DLinear(cfg)\n",
    "model2 = DLinear2(cfg)\n",
    "model.train()\n",
    "model2.train()\n",
    "state_dict = model.state_dict()\n",
    "model2.load_state_dict(state_dict)\n",
    "out1 = model(dummpy)\n",
    "out2 = model2(dummpy)\n",
    "#check all parameters are same\n",
    "flag = True\n",
    "for p1, p2 in zip(model.parameters(), model2.parameters()):\n",
    "    if not torch.allclose(p1, p2, atol=1e-4):\n",
    "        flag = False\n",
    "        break\n",
    "print(\"Parameters match:\", flag)\n",
    "print(out1.shape, out2.shape)\n",
    "print(torch.allclose(out1, out2, atol=1e-12))  #\n",
    "target = torch.randn(8, 48, 2304) \n",
    "loss1 = F.mse_loss(out1, target)\n",
    "loss2 = F.mse_loss(out2, target)\n",
    "\n",
    "loss1.backward()\n",
    "loss2.backward()\n",
    "optim = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "optim2 = torch.optim.SGD(model2.parameters(), lr=1e-3)\n",
    "optim.step()\n",
    "optim2.step()\n",
    "\n",
    "# Check if the gradients are the same\n",
    "flag = True\n",
    "for (name1, p1), (name2, p2) in zip(model.named_parameters(), model2.named_parameters()):\n",
    "    if p1.grad is None or p2.grad is None:\n",
    "        print(f\"Gradient is None for: {name1}, {name2}\")\n",
    "        assert p1.grad is None and p2.grad is None, \"both gradients should be None\"\n",
    "        print(\"skipping gradient check for None gradients\")\n",
    "        continue\n",
    "    if not torch.allclose(p1.grad, p2.grad, atol=1e-4):\n",
    "        flag = False\n",
    "        break\n",
    "print(\"Gradients match:\", flag)\n",
    "\n",
    "out1_again = model(dummpy)\n",
    "out2_again = model2(dummpy)\n",
    "print(torch.allclose(out1_again, out2_again, atol=1e-12))  # should be True after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, stride=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_ch)\n",
    "        self.act1 = nn.GELU()\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(out_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_ch)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_ch != out_ch:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_ch, out_ch, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_ch)\n",
    "            )\n",
    "            \n",
    "        self.act2 = nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = self.shortcut(x)\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.act1(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        out += shortcut\n",
    "        return self.act2(out)\n",
    "\n",
    "class UpsampleBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, scale_factor):\n",
    "        super().__init__()\n",
    "        self.upsample = nn.Upsample(scale_factor=scale_factor, mode='nearest')\n",
    "        self.resblock = ResidualBlock(in_ch, out_ch, stride=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resblock(self.upsample(x))\n",
    "\n",
    "class ConvAutoencoder(nn.Module):\n",
    "    def __init__(self, in_ch=1, latent_dim=512):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Encoder: 128 → 64 → 32 → 16 → 4 → 1\n",
    "        self.enc1 = ResidualBlock(in_ch,   64, stride=2)  # 128 → 64\n",
    "        self.enc2 = ResidualBlock(64,     128, stride=2)  # 64 → 32\n",
    "        self.enc3 = ResidualBlock(128,    256, stride=2)  # 32 → 16\n",
    "        self.enc4 = ResidualBlock(256,    512, stride=4)  # 16 → 4\n",
    "        self.enc5 = ResidualBlock(512,   1024, stride=4)  # 4 → 1\n",
    "\n",
    "        self.flatten = nn.Flatten()                     # (B,1024,1,1) → (B,1024)\n",
    "        self.fc_enc = nn.Linear(1024, latent_dim)\n",
    "\n",
    "        self.fc_dec = nn.Linear(latent_dim, 1024)\n",
    "        self.unflatten = nn.Unflatten(1, (1024, 1, 1))   # (B,1024) → (B,1024,1,1)\n",
    "        self.dec_init_conv = ResidualBlock(1024, 1024, stride=1)\n",
    "\n",
    "        # Decoder: 1 → 4 → 16 → 32 → 64 → 128\n",
    "        self.dec1 = UpsampleBlock(1024, 512, scale_factor=4)  # 1 → 4\n",
    "        self.dec2 = UpsampleBlock(512,  256, scale_factor=4)  # 4 → 16\n",
    "        self.dec3 = UpsampleBlock(256,  128, scale_factor=2)  # 16 → 32\n",
    "        self.dec4 = UpsampleBlock(128,   64, scale_factor=2)  # 32 → 64\n",
    "        \n",
    "        self.final_upsample = nn.Upsample(scale_factor=2, mode='nearest') # 64 → 128\n",
    "        self.final_conv = nn.Conv2d(64, in_ch, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = self.enc1(x)\n",
    "        x = self.enc2(x)\n",
    "        x = self.enc3(x)\n",
    "        x = self.enc4(x)\n",
    "        x = self.enc5(x)\n",
    "        x = self.flatten(x)\n",
    "        z = self.fc_enc(x)\n",
    "        return z\n",
    "\n",
    "    def decode(self, z):\n",
    "        x = self.fc_dec(z)\n",
    "        x = self.unflatten(x)\n",
    "        x = self.dec_init_conv(x)\n",
    "        x = self.dec1(x)\n",
    "        x = self.dec2(x)\n",
    "        x = self.dec3(x)\n",
    "        x = self.dec4(x)\n",
    "        x = self.final_upsample(x)\n",
    "        x = self.final_conv(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encode(x)\n",
    "        reconstruction = self.decode(z)\n",
    "        return reconstruction, z\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import torch\n",
    "    model = ConvAutoencoder()\n",
    "    x = torch.randn(8, 1, 128, 128)  # Batch of 8 images with 1 channel, 128x128 size\n",
    "    recon, z = model(x)\n",
    "    print(\"Input shape:\", x.shape)\n",
    "    print(\"Reconstruction shape:\", recon.shape)\n",
    "    print(\"Latent vector shape:\", z.shape)\n",
    "    params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    params_in_million = params / 1e6\n",
    "    print(f\"Total trainable parameters: {params_in_million:.2f} million\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/vatsal/NWM/sevir_lr/data/vil/2017/SEVIR_VIL_RANDOMEVENTS_2017_0501_0831.h5\"\n",
    "import h5py\n",
    "data = h5py.File(path, 'r')\n",
    "vil = data['vil'][:]\n",
    "print(\"Shape of VIL data:\", vil.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "os.environ['WANDB_API_KEY'] = '041eda3850f131617ee1d1c9714e6230c6ac4772'\n",
    "datetime.datetime.now().strftime(\"_%Y%m%d_%H%M%S\")\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "exp_name = \"test_run_xyz\"\n",
    "save_dir = os.path.join(\"experiments\", \"test\", exp_name + datetime.datetime.now().strftime(\"_%Y%m%d_%H%M%S\"))\n",
    "version = \"v1.0\"\n",
    "logger = WandbLogger(project=\"delete_it\", name=\"test_run\", save_dir=save_dir, version=version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline.datasets.sevire.sevir import SEVIRLightningDataModule\n",
    "data = SEVIRLightningDataModule(dataset_name=\"sevir_lr\", num_workers=0, batch_size=1, seq_len=1, stride=1, layout='NTHW')\n",
    "data.setup()\n",
    "data.prepare_data()\n",
    "train_loader = data.train_dataloader()\n",
    "sample1 = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline.datasets.sevire.sevir import SEVIRLightningDataModule\n",
    "data2 = SEVIRLightningDataModule(dataset_name=\"sevir_lr\", num_workers=8, batch_size=8, seq_len=12, stride=20, layout='NTHW')\n",
    "data2.setup()\n",
    "data2.prepare_data()\n",
    "train_loader2 = data2.train_dataloader()\n",
    "sample2 = next(iter(train_loader2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2_dict = {}\n",
    "print(len(train_loader2))\n",
    "from tqdm import tqdm\n",
    "for epoch in range(2):\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    if epoch == 0:\n",
    "        for idx, sample in tqdm(enumerate(train_loader2)):\n",
    "            data = sample['vil']\n",
    "            data2_dict[data] = idx\n",
    "    else:\n",
    "        for sample in tqdm(train_loader2):\n",
    "            data = sample['vil']\n",
    "            idx = -1\n",
    "            for i, d in enumerate(data2_dict.keys()):\n",
    "                if torch.allclose(d, data, atol=1e-12):\n",
    "                    idx = i\n",
    "                    break\n",
    "            print(f\"Found data at index: {idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline.datasets.sevire.sevir import SEVIRLightningDataModule\n",
    "data3 = SEVIRLightningDataModule(dataset_name=\"sevir_lr\", num_workers=0, batch_size=8, seq_len=1, stride=1, layout='NTHW')\n",
    "data3.setup()\n",
    "data3.prepare_data()\n",
    "train_loader3 = data2.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample2, sample3 in zip(train_loader2, train_loader3):\n",
    "    data2 = sample2['vil']\n",
    "    data3 = sample3['vil']\n",
    "    if not torch.allclose(data2, data3, atol=1e-12):\n",
    "        print(\"Data mismatch found!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample3 = next(iter(train_loader3))\n",
    "import torch\n",
    "torch.allclose(sample2['vil'], sample3['vil'], atol=1e-12) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = []\n",
    "import torch\n",
    "for sample in train_loader2:\n",
    "    data = sample['vil']\n",
    "    datas.append(data)\n",
    "print(len(datas))\n",
    "for sample in train_loader3:\n",
    "    data = sample['vil']\n",
    "    idx = -1\n",
    "    for i, d in enumerate(datas):\n",
    "        if torch.allclose(data, d, atol=1e-12):\n",
    "            idx = i\n",
    "            break\n",
    "    if idx != -1:\n",
    "        print(f\"Found matching data at index {idx}\")\n",
    "    else:\n",
    "        print(\"No matching data found _______________________________-\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = []\n",
    "import torch\n",
    "for sample in train_loader2:\n",
    "    data = sample['vil']\n",
    "    datas.append(data)\n",
    "print(len(datas))\n",
    "for sample in train_loader2:\n",
    "    data = sample['vil']\n",
    "    idx = -1\n",
    "    for i, d in enumerate(datas):\n",
    "        if torch.allclose(data, d, atol=1e-12):\n",
    "            idx = i\n",
    "            break\n",
    "    if idx != -1:\n",
    "        print(f\"Found matching data at index {idx}\")\n",
    "    else:\n",
    "        print(\"No matching data found _______________________________-\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = []\n",
    "import torch\n",
    "for sample in train_loader2:\n",
    "    data = sample['vil']\n",
    "    for bdata in data:\n",
    "        datas.append(bdata)\n",
    "print(len(datas))\n",
    "for sample in train_loader3:\n",
    "    data = sample['vil']\n",
    "    for bdata in data:\n",
    "        idx = -1\n",
    "        for i, d in enumerate(datas):\n",
    "            if torch.allclose(bdata, d, atol=1e-12):\n",
    "                idx = i\n",
    "                break\n",
    "        if idx != -1:\n",
    "            print(f\"Found matching data at index {idx}\")\n",
    "        else:\n",
    "            print(\"No matching data found _______________________________-\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import glob\n",
    "\n",
    "def cleanup_checkpoints_and_wandb(root_dir):\n",
    "    total_freed = 0\n",
    "    # Delete .ckpt files (keep most recent)\n",
    "    for dirpath, dirnames, _ in os.walk(root_dir):\n",
    "        if os.path.basename(dirpath) == \"checkpoints\":\n",
    "            ckpts = glob.glob(os.path.join(dirpath, \"*.ckpt\"))\n",
    "            if len(ckpts) <= 1:\n",
    "                continue\n",
    "            ckpts = [(f, os.path.getmtime(f)) for f in ckpts]\n",
    "            ckpts.sort(key=lambda x: x[1], reverse=True)\n",
    "            to_delete = ckpts[1:]  # keep most recent\n",
    "\n",
    "            for fpath, _ in to_delete:\n",
    "                try:\n",
    "                    size_mb = os.path.getsize(fpath) / (1024 * 1024)\n",
    "                    os.remove(fpath)\n",
    "                    total_freed += size_mb\n",
    "                    print(f\"Deleted .ckpt: {fpath} ({size_mb:.2f} MB)\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to delete {fpath}: {e}\")\n",
    "\n",
    "    # Delete all .wandb files\n",
    "    for dirpath, _, filenames in os.walk(root_dir):\n",
    "        for fname in filenames:\n",
    "            if fname.endswith(\".wandb\"):\n",
    "                fpath = os.path.join(dirpath, fname)\n",
    "                try:\n",
    "                    size_mb = os.path.getsize(fpath) / (1024 * 1024)\n",
    "                    os.remove(fpath)\n",
    "                    total_freed += size_mb\n",
    "                    print(f\"Deleted .wandb: {fpath} ({size_mb:.2f} MB)\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to delete {fpath}: {e}\")\n",
    "\n",
    "    print(f\"Total space freed: {total_freed:.2f} MB\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cleanup_checkpoints_and_wandb(\"/home/vatsal/NWM/weatherforecasting\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 128, 128]) torch.Size([1, 1, 128, 128]) torch.Size([1, 2048])\n",
      "Total trainable parameters: 207.00 million\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_ch: int,\n",
    "                 out_ch: int,\n",
    "                 stride: int = 1,\n",
    "                 groups: int = 8):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_ch,\n",
    "                               out_ch,\n",
    "                               kernel_size=3,\n",
    "                               stride=stride,\n",
    "                               padding=1,\n",
    "                               bias=False)\n",
    "        self.norm1 = nn.GroupNorm(groups, out_ch)\n",
    "        self.act1  = nn.GELU()\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_ch,\n",
    "                               out_ch,\n",
    "                               kernel_size=3,\n",
    "                               stride=1,\n",
    "                               padding=1,\n",
    "                               bias=False)\n",
    "        self.norm2 = nn.GroupNorm(groups, out_ch)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_ch != out_ch:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_ch, out_ch, 1, stride, bias=False),\n",
    "                nn.GroupNorm(groups, out_ch)\n",
    "            )\n",
    "\n",
    "        self.act2 = nn.GELU()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        skip = self.shortcut(x)\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.norm1(out)\n",
    "        out = self.act1(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.norm2(out)\n",
    "\n",
    "        out += skip\n",
    "        return self.act2(out)\n",
    "\n",
    "\n",
    "class UpsampleBlock(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_ch: int,\n",
    "                 out_ch: int):\n",
    "        super().__init__()\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.res = ResidualBlock(in_ch, out_ch, stride=1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.res(self.up(x))\n",
    "\n",
    "\n",
    "class ConvAutoencoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_ch: int = 1,\n",
    "                 latent_dim: int = 2048):\n",
    "        super().__init__()\n",
    "\n",
    "        # ---------- Encoder ----------\n",
    "        # 128 -> 64 -> 32 -> 16 -> 8 -> 4 -> 2 -> 1\n",
    "        self.enc1 = ResidualBlock(in_ch,   64,  stride=2)  # 128→64\n",
    "        self.enc2 = ResidualBlock(64,     128, stride=2)   # 64→32\n",
    "        self.enc3 = ResidualBlock(128,    256, stride=2)   # 32→16\n",
    "        self.enc4 = ResidualBlock(256,    512, stride=2)   # 16→8\n",
    "        self.enc5 = ResidualBlock(512,   1024, stride=2)   # 8→4\n",
    "        self.enc6 = ResidualBlock(1024,  2048, stride=2)   # 4→2\n",
    "        self.enc7 = ResidualBlock(2048,  2048, stride=2)   # 2→1  (B,2048,1,1)\n",
    "\n",
    "        self.flatten = nn.Flatten()            # (B,2048)\n",
    "        self.fc_enc  = nn.Linear(2048, latent_dim)\n",
    "\n",
    "        # ---------- Decoder ----------\n",
    "        self.fc_dec  = nn.Linear(latent_dim, 2048)\n",
    "        self.unflatten = nn.Unflatten(1, (2048, 1, 1))\n",
    "\n",
    "        # 1 -> 2 -> 4 -> 8 -> 16 -> 32 -> 64 -> 128\n",
    "        self.dec1 = UpsampleBlock(2048, 1024)  # 1→2\n",
    "        self.dec2 = UpsampleBlock(1024,  512)  # 2→4\n",
    "        self.dec3 = UpsampleBlock(512,   256)  # 4→8\n",
    "        self.dec4 = UpsampleBlock(256,   128)  # 8→16\n",
    "        self.dec5 = UpsampleBlock(128,    64)  # 16→32\n",
    "        self.dec6 = UpsampleBlock(64,     64)  # 32→64\n",
    "        self.dec7 = UpsampleBlock(64,     32)  # 64→128\n",
    "        self.final_conv = nn.Conv2d(32, in_ch, 3, 1, 1)\n",
    "\n",
    "    # ---------- Forward helpers ----------\n",
    "    def encode(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.enc1(x)\n",
    "        x = self.enc2(x)\n",
    "        x = self.enc3(x)\n",
    "        x = self.enc4(x)\n",
    "        x = self.enc5(x)\n",
    "        x = self.enc6(x)\n",
    "        x = self.enc7(x)\n",
    "        x = self.flatten(x)\n",
    "        return self.fc_enc(x)\n",
    "\n",
    "    def decode(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.fc_dec(z)\n",
    "        x = self.unflatten(x)\n",
    "        x = self.dec1(x)\n",
    "        x = self.dec2(x)\n",
    "        x = self.dec3(x)\n",
    "        x = self.dec4(x)\n",
    "        x = self.dec5(x)\n",
    "        x = self.dec6(x)\n",
    "        x = self.dec7(x)\n",
    "        x = self.final_conv(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        z = self.encode(x)\n",
    "        recon = self.decode(z)\n",
    "        return recon, z\n",
    "\n",
    "model = ConvAutoencoder(in_ch=1, latent_dim=2048).cuda()\n",
    "x = torch.randn(1, 1, 128, 128).cuda()\n",
    "recon, z = model(x)\n",
    "print(x.shape, recon.shape, z.shape)  # torch.Size([1, 1, 128, 128]) ... torch.Size([1, 2048])\n",
    "params_in_million = sum(p.numel() for p in model.parameters() if p.requires_grad) / 1e6\n",
    "print(f\"Total trainable parameters: {params_in_million:.2f} million\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total .ckpt size: 5.23 GB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def get_ckpt_total_size(root_dir):\n",
    "    total_size = 0\n",
    "    for dirpath, _, filenames in os.walk(root_dir):\n",
    "        for fname in filenames:\n",
    "            if fname.endswith('.ckpt'):\n",
    "                fpath = os.path.join(dirpath, fname)\n",
    "                total_size += os.path.getsize(fpath)\n",
    "    return total_size\n",
    "\n",
    "def format_size(bytes_size):\n",
    "    for unit in ['B', 'KB', 'MB', 'GB', 'TB']:\n",
    "        if bytes_size < 1024:\n",
    "            return f\"{bytes_size:.2f} {unit}\"\n",
    "        bytes_size /= 1024\n",
    "    return f\"{bytes_size:.2f} PB\"\n",
    "\n",
    "root = \"/home/vatsal/NWM\"\n",
    "total = get_ckpt_total_size(root)\n",
    "print(\"Total .ckpt size:\", format_size(total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vatsal/NWM/weatherforecasting: 20.60 GB\n",
      "/home/vatsal/NWM/weather: 11.77 GB\n",
      "/home/vatsal/NWM/sevir_lr: 8.77 GB\n",
      "/home/vatsal/NWM/PreDiff: 0.36 GB\n",
      "/home/vatsal/NWM/DiffCast: 0.16 GB\n",
      "/home/vatsal/NWM/AlphaPre: 0.00 GB\n",
      "/home/vatsal/NWM/.vscode: 0.00 GB\n",
      "/home/vatsal/NWM/wandb: 0.00 GB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def get_dir_size(path):\n",
    "    total = 0\n",
    "    for dirpath, _, filenames in os.walk(path):\n",
    "        for f in filenames:\n",
    "            fpath = os.path.join(dirpath, f)\n",
    "            try:\n",
    "                if not os.path.islink(fpath) and os.path.isfile(fpath):\n",
    "                    total += os.path.getsize(fpath)\n",
    "            except:\n",
    "                continue\n",
    "    return total\n",
    "\n",
    "def list_top_dirs(root_dir, top_n=20):\n",
    "    dir_sizes = []\n",
    "    for entry in os.scandir(root_dir):\n",
    "        if entry.is_dir(follow_symlinks=False):\n",
    "            size = get_dir_size(entry.path)\n",
    "            dir_sizes.append((entry.path, size))\n",
    "    \n",
    "    dir_sizes.sort(key=lambda x: x[1], reverse=True)\n",
    "    for path, size in dir_sizes[:top_n]:\n",
    "        print(f\"{path}: {size / (1024**3):.2f} GB\")\n",
    "\n",
    "# Example usage\n",
    "list_top_dirs(\"/home/vatsal/NWM\", top_n=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 512])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        # 16×16 → 8×8 → 4×4 → 2×2 → 1×1  (all with convolutions)\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3, stride=2, padding=1),   # (B,128, 8, 8)\n",
    "            nn.SiLU(inplace=True),\n",
    "            nn.Conv2d(128, 256, 3, stride=2, padding=1),  # (B,256, 4, 4)\n",
    "            nn.SiLU(inplace=True),\n",
    "            nn.Conv2d(256, 512, 3, stride=2, padding=1),  # (B,512, 2, 2)\n",
    "            nn.SiLU(inplace=True),\n",
    "            nn.Conv2d(512, 1024, 3, stride=2, padding=1),\n",
    "            nn.SiLU(inplace=True),\n",
    "        )\n",
    "        self.conv_out = nn.Conv2d(1024, 1024, 1, 1, 0)   # (B,1024, 1, 1)\n",
    "        self.fc = nn.Linear(1024, latent_dim)             # (B, latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)        # (B,1024,1,1)\n",
    "        x = self.conv_out(x)    # (B,1024,1,1)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        z = self.fc(x)\n",
    "        return z\n",
    "model = Encoder(latent_dim=512)\n",
    "x = torch.randn(2, 64, 16, 16)  # Example input\n",
    "z = model(x)\n",
    "print(\"Input shape:\", z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading: 100%|██████████| 1440/1440 [00:00<00:00, 2760.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting PCA on (36000, 16384)\n",
      "Need k=1062 PCs for 95 % variance\n",
      "Smallest 3-D latent tensor (H/r, W/r, c): (64, 64, 8) volume = 32768\n"
     ]
    }
   ],
   "source": [
    "import torch, numpy as np, h5py, tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "import tqdm\n",
    "HDF5_PATH   = '/home/vatsal/NWM/sevir_lr/data/vil/2017/SEVIR_VIL_RANDOMEVENTS_2017_0501_0831.h5'   \n",
    "DS_NAME     = 'vil'           \n",
    "SAMPLE_STEP = 1         \n",
    "PATCH_SIZE  = 128            \n",
    "GPU         = torch.cuda.is_available()\n",
    "# --------------------------------\n",
    "\n",
    "frames = []\n",
    "with h5py.File(HDF5_PATH, 'r') as f:\n",
    "    imgs = f[DS_NAME][:]                     # (T, H, W) or (T, C, H, W)\n",
    "    if imgs.ndim == 4 and imgs.shape[1] == 1:\n",
    "        imgs = imgs[:, 0]\n",
    "    imgs = imgs[::SAMPLE_STEP]\n",
    "    for t in tqdm.tqdm(imgs, desc='loading'):\n",
    "        for x in range(0, t.shape[-1]):\n",
    "            img = t[..., x]\n",
    "            frames.append(img.flatten())\n",
    "X = np.stack(frames)        # (N, 16384) for 128²\n",
    "\n",
    "# 2. Exact PCA on GPU (or CPU)\n",
    "print('Fitting PCA on', X.shape)\n",
    "pca = PCA().fit(X)\n",
    "\n",
    "# 3. Energy curve\n",
    "cum = np.cumsum(pca.explained_variance_ratio_)\n",
    "k95 = int(np.searchsorted(cum, 0.95)) + 1\n",
    "print(f'Need k={k95} PCs for 95 % variance')\n",
    "\n",
    "# 4. Latent tensor bound\n",
    "H, W = PATCH_SIZE, PATCH_SIZE\n",
    "# Empirical rule: latent volume ≥ k95\n",
    "# Let r = spatial downsample ratio, c = channels\n",
    "def smallest_latent(k, r_list=[2,4,8]):\n",
    "    for r in r_list:\n",
    "        for c in [8,16,32,64]:\n",
    "            if (H//r)*(W//r)*c >= k:\n",
    "                return (H//r, W//r, c), (H//r)*(W//r)*c\n",
    "    return None, None\n",
    "shape, vol = smallest_latent(k95)\n",
    "print('Smallest 3-D latent tensor (H/r, W/r, c):', shape, 'volume =', vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H=64, W=64, c=8\n",
      "H=64, W=64, c=16\n",
      "H=64, W=64, c=32\n",
      "H=64, W=64, c=64\n",
      "H=64, W=64, c=128\n",
      "H=64, W=64, c=256\n",
      "H=32, W=32, c=8\n",
      "H=32, W=32, c=16\n",
      "H=32, W=32, c=32\n",
      "H=32, W=32, c=64\n",
      "H=32, W=32, c=128\n",
      "H=32, W=32, c=256\n",
      "H=16, W=16, c=8\n",
      "H=16, W=16, c=16\n",
      "H=16, W=16, c=32\n",
      "H=16, W=16, c=64\n",
      "H=16, W=16, c=128\n",
      "H=16, W=16, c=256\n",
      "H=8, W=8, c=32\n",
      "H=8, W=8, c=64\n",
      "H=8, W=8, c=128\n",
      "H=8, W=8, c=256\n",
      "H=4, W=4, c=128\n",
      "H=4, W=4, c=256\n",
      "Smallest 3-D latent tensor (H/r, W/r, c): None volume = None\n"
     ]
    }
   ],
   "source": [
    "H, W = PATCH_SIZE, PATCH_SIZE\n",
    "# Empirical rule: latent volume ≥ k95\n",
    "# Let r = spatial downsample ratio, c = channels\n",
    "def smallest_latent(k, r_list=[2,4,8,16,32,64,128]):\n",
    "    for r in r_list:\n",
    "        for c in [8,16,32,64,128,256]:\n",
    "            if (H//r)*(W//r)*c >= k:\n",
    "                print(f\"H={H//r}, W={W//r}, c={c}\")\n",
    "                # return (H//r, W//r, c), (H//r)*(W//r)*c\n",
    "    return None, None\n",
    "shape, vol = smallest_latent(k95)\n",
    "print('Smallest 3-D latent tensor (H/r, W/r, c):', shape, 'volume =', vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "earthformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
